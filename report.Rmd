---
title: "Report"
author: "Lukas Nick"
date: "30. Oktoober 2015"
output: html_document
---

```{r, echo=FALSE}

# Setup
setwd('Documents/ml/datascience/capstone-project/')

# load libraries
library(ggplot2)
source('utils.R')
source('db.R')
source('multiplot.R')
library(Hmisc)
library(MASS)
```


# Title

[A brief description of what you've done]

This study evaluates whether a new star rating is related to the average of older ratings. It also considers whether this relationship is stronger than the country factor or the number of reviews at the time of the new rating. 

Furthermore, it addresses the question whether ratings that deviate from the average of the earlier ratings are more often voted as 'useful' than non deviating ratings.

The first two questions are tackled using ordered logit models, the third question simply correlations the deviation of a new rating with the number of 'useful' votes that rating got.

# Introduction

[A description of the question/problem and the rationale for studying it]

Most users of Yelp, when they review a business and judge it with a rating (i.e. a number of "stars" between 1 and 5), they have already seen the older reviews of that business, since they are displayed on the same page. Social Psychology suggests that other people's opinions influence ones own judgment (see, among many, for example [^aesch](Aesch, 1952)). Therefore it seems reasonable to assume that older ratings, corresponding to other people's options, could influence a user's new rating.

If that was the case, designers of Yelp or similar services that use any kind of rating might want to look into ways of "blind" voting, so that new raters can see other users' ratings only _after_ having stated their own rating.

On obvious problem when comparing previous ratings with new ratings is that we have to assume a "business factor" influencing both previous ratings and older ratings: if the business is, let's say, in general "good", then both previous and the new user will tend to rate it higher, and vice versa. We therefore need a way to seperate a general "business factor" from a "social factor".

To achieve this, two measures of previous ratings were calculated: the average of the last 20 ratings (named the "recent average rating"), and the average of all the older ratings (named "base average rating"). The base average rating is thought to represent the "general business factor", and the recent average rating is considered the one that has some social influence (assuming that rarely users go further back than one page to look at older ratings, especially on a mobile device).

Those two factors were distinguished with a multivariate model.

<Was there exploratory data analysis (plots, summary tables) presented that interrogates the question of interest?>

< 
  -> show histogram of stars
  -> show double-plot last.rating vs bar & rar 
  
  
>

# Methods and Data

[Describe how you used the data and the type of analytic methods that you used; it's okay to be a bit technical here but clarity is important]

## Dataset

To study this question, I used the data from the [Yelp Dataset Challenge](http://www.yelp.com/dataset_challenge): it contains 1.5M reviews of 481 thousend businesses, by 366 thousend users. 

To better handle this amount of data, I used a small [Rails application](https://github.com/lunas/yelp_seeder) to seed the data (that is available in JSON format) into a PostgreSQL database.

I then created a table that lists each business in a row, and in separate columns:

* the latest rating; this is the rating of the new user that will be compared to previous ratings
* the recent average rating: the average of the ratings of the most recent 21 reviews (excluding the latest rating)
* the base average rating: the average of all older reviews (i.e. all ratings excluding the latest 21 ratings)
* the number of reviews at the time of the latest rating
* the number of times the latest rating got voted as 'useful'
* the country of the business: either USA, Canada, Great Britain or Germany.

```{r, echo=FALSE, cache=TRUE}

NUM.RECENT.RATINGS = 20

sql <- "SELECT rb.business_id, 
        array_to_string( array_agg( rb.date || ';' || rb.stars || ';' || rb.useful || ';' || rb.country ), ',') as ratings, 
        count(rb.id) as num_reviews    
        FROM (SELECT r.business_id, r.date, r.stars, (votes->>'useful')::text::int as useful, b.state, r.id,
              CASE WHEN state IN ('BW', 'RP') THEN 'DE'             
                   WHEN state IN ('EDH', 'ELN', 'FIF','HAM', 'KHL', 'MLN', 'SCB','XGL') THEN 'GB'
                   WHEN state IN ('ON','QC') THEN 'CA'
                   ELSE 'US' END as country
              FROM reviews r INNER JOIN businesses b USING (business_id) 
              ORDER BY business_id, date ASC) rb 
        GROUP BY rb.business_id
        ORDER BY rb.business_id"
agg.ratings <- query.result(sql)

# extract the information stored in the ratings field and created separate fields
calculate_avgs <- function(rating_string) {
  ratings <- (strsplit(rating_string, ',', fixed=T))[[1]]
  num.ratings <- length(ratings)
  base.range <- 1 : (num.ratings-NUM.RECENT.RATINGS-1)
  recent.range <- (num.ratings-NUM.RECENT.RATINGS) : (num.ratings -1)
  base.ratings <- ratings[base.range]
  recent.ratings <- ratings[recent.range]
  base.avg   <- mean(sapply(base.ratings,   function(rtg){ return(as.numeric( strsplit(rtg, ';')[[1]][2] )) }))
  recent.avg <- mean(sapply(recent.ratings, function(rtg){ return(as.numeric( strsplit(rtg, ';')[[1]][2] )) }))
  recent.sd  <- sd(  sapply(recent.ratings, function(rtg){ return(as.numeric( strsplit(rtg, ';')[[1]][2] )) }))
  last.rating <- as.numeric( strsplit( ratings[ num.ratings ], ';')[[1]][2] )  # stars of latest rating
  useful      <- as.numeric( strsplit( ratings[ num.ratings ], ';')[[1]][3] )  # usefulness of latest rating
  country     <- ( strsplit( ratings[1], ';')[[1]][4] )            # country of first rating (the same for all ratings) 
  return( list(base.avg = base.avg, recent.avg = recent.avg, recent.sd = recent.sd, last.rating = last.rating, useful=useful, country=country))
}

# drop businesses with fewer then 2xNUM.RECENT.RATINGS
agg.ratings <- agg.ratings[ agg.ratings$num_reviews > 2*NUM.RECENT.RATINGS, ]
calculated.cols <- t(sapply( agg.ratings$ratings, calculate_avgs ))
row.names(calculated.cols) <- c()  # remove the row names
calculated.df <- as.data.frame(calculated.cols)
agg.ratings[,4:9] <- calculated.df
names(agg.ratings)[3:9] <- cbind("num.reviews", "base.avg.rating", "recent.avg.rating", "recent.sd", "last.rating", "useful", "country")
# convert lists to numeric/character:
agg.ratings$base.avg.rating <- as.numeric(agg.ratings$base.avg.rating)
agg.ratings$recent.avg.rating <- as.numeric(agg.ratings$recent.avg.rating)
agg.ratings$recent.sd <- as.numeric(agg.ratings$recent.sd)
agg.ratings$last.rating <- as.numeric(agg.ratings$last.rating)
agg.ratings$useful <- as.numeric(agg.ratings$useful)
agg.ratings$country <- as.character(agg.ratings$country)

```

To calculate averages of the latest 20 ratings and meaningful averages of the even older base ratings, we need businesses with at least 40 reviews (2 * 20). Therefore businesses with fewer reviews were filtered out.
```{r, echo=FALSE}
head(agg.ratings[,c('business_id', 'num.reviews', 'base.avg.rating', 'recent.avg.rating', 'last.rating', 'useful','country', 'recent.sd')])
```

The last column, 'recent.sd', contains the standard deviation of the 20 most recent ratings. It will be used to calculate the deviation of the latest rating from the 20 most recent ratings in terms of their standard calculation.

## Data exploration

```{r, echo=FALSE}
h2 <- qplot(base.avg.rating,   data = agg.ratings, geom = "histogram")
h3 <- qplot(recent.avg.rating, data = agg.ratings, geom = "histogram")
h4 <- qplot(last.rating, data = agg.ratings, geom = "histogram")
multiplot(h2, h4, h3, cols = 2)
```

The distribution of both base.avg.rating and recent.avg.rating is close to a normal. Not so the distribution of the latest ratings.

How are the ratings distributed in the three countries?

Amount of reviews per country:
```{r, echo=FALSE}
table(agg.ratings$country, agg.ratings$last.rating)
```

```{r, echo=FALSE}
h1 <- qplot(log(last.rating),  data = agg.ratings, geom = "histogram", facets = country ~ .) + scale_y_continuous(trans = "log2")
h1 
```

The distribution of last.rating seems to be roughly similar in the USA, Canada and Great Britain. There are no german businesses any more: all of them had less than 40 reviews and were therefore filtered out.

Plot the base.avg.rating and recent.avg.rating per stars (last-rating):
```{r, echo=FALSE}
p1 <- ggplot(agg.ratings, aes(last.rating, base.avg.rating)) + geom_point(alpha=1/100) 
p2 <- ggplot(agg.ratings, aes(last.rating, recent.avg.rating)) + geom_point(alpha=1/100)
multiplot(p1, p2, cols = 2)
```

```{r, echo=FALSE}
p <-ggplot(agg.ratings, aes(x = last.rating, y = recent.avg.rating)) +
      geom_boxplot(size = .75) +
      geom_jitter(alpha = .5) +
      facet_grid(country ~ ., margins = TRUE) +
      theme(axis.text.x = element_text(hjust = 1, vjust = 1))
# no need to print this one
```

There seems to be a small correlation between the latest rating and the both the base average rating and the recent average rating.

Let's calculate the Spearman correlation (since the latest rating is not normally distributed):
```{r, echo=FALSE}
rcorr(as.matrix(agg.ratings[,c("base.avg.rating", "recent.avg.rating", "last.rating")]), type="spearman")
```

To have a preliminary look at the interaction of those average ratings with the latest rating, let's do a quick multiple regression that predicts latest.rating by recent average rating and controls for base average rating:
```{r}
summary( lm(agg.ratings$last.rating ~ agg.ratings$base.avg.rating + agg.ratings$recent.avg.rating) )
```

Is the recent.avg.rating term even necessary?
```{r, echo=FALSE}
fit1r <- lm( last.rating ~ base.avg.rating, data=agg.ratings)
fit2r <- update( fit1r, lm( last.rating ~ base.avg.rating + recent.avg.rating, data=agg.ratings) )
anova(fit1r, fit2r)
```

-> Yes.

As an additional question, we want to know whether deviating ratings are considered more useful. What is the distribution of these variables?
```{r, echo=FALSE}
h4 <- qplot(useful,            data = agg.ratings, geom = "histogram") 
h5 <- qplot(recent.sd,         data = agg.ratings, geom = "histogram") 
multiplot(h4, h5, cols=2)
```

Is there any hint of a relationship graphically?
```{r, echo=FALSE}
qplot(abs(agg.ratings$recent.avg.rating - agg.ratings$last.rating), agg.ratings$useful)
```

This looks rather as if less deviation ratings were voted more 'useful'.

## Methods

Since the dependent variable, the latest rating, is discrete, not normally distributed, and only ranges from 1 to 5, multiple regression is not the ideal method. Therefore an ordered logistic regression model was calculated.

### Ordered logistic regression

Ordered logistic regression is a regression model for ordinal dependent variables* (as our ``latest.rating`` variable, the "stars" given in a review). It uses maximum likelihood to estimate the coefficients.

```{r, echo=FALSE}
# Following http://www.ats.ucla.edu/stat/r/dae/ologit.htm

# First add a new variable to agg.ratings that is just last.rating converted to a factor, since polr requires this
agg.ratings$stars <- as.factor(agg.ratings$last.rating)
```

The function ``polr`` from the library MASS was used to estimate the coefficients of the ologit model. To compare the influence of the base average rating and the recent average rating with the influence of the number of reviews at the time of the latest rating, ``num.reviews`` was included in the ordered logit model as well.

```{r}
m <- polr(stars ~ base.avg.rating + recent.avg.rating + num.reviews, data = agg.ratings, Hess=TRUE)
```

The variable ``country`` was not included in the model since exploratory analysis showed that the distribution of CA and USA looks very similar, and both CA and GB have to small cell sizes for the ologit model to be stable or meaningful.

### Deviations of latest rating and 'usefulness'

Finally, to see whether ratings that differ from earlier ratings are voted more often as 'useful', the difference of the latest rating in terms of the standard deviation of the 20 most recent ratings was calculated. This new variable, dubbed simply 'deviation', was then correlation with the number the latest rating got voted as 'useful'.

# Results

## Base average rating, recent average rating, number of reviews and the last rating

```{r, echo=FALSE}
# Following http://www.ats.ucla.edu/stat/r/dae/ologit.htm
#summary(m)

# Calculate p-values for the coefficients:
coefficients <- coef(summary(m))

# calculate and store p values
p <- pnorm(abs(coefficients[, "t value"]), lower.tail = FALSE) * 2
# combined table
(coefficients <- cbind(coefficients, "p value" = p))
```

We see that both the base average rating and the recent average rating exhibit a significant influence on a new rating, whereas the number of reviews seems to be irrelevant.

To easier interpret the coeffient, let's convert them to odds rations and calculate there confidence intervals:
```{r, echo=FALSE}
# Get confidence intervals for the coefficients: 
ci <- confint(m) # default method gives profiled CIs

# odds ratios
# exp(coef(m))
# Confidence intervals for the odds ratios
exp(cbind(OddsRatios = coef(m), ci))
```

So we can expect an increase in the base average rating of one start to increase the _odds_ for the lastest rating to get a higher star-rating to rise by 82%.

Likewise, an increase in the recent average rating of one star raises the _odds_ for the latest rating to get a (any) higher rating more than twice (2.14).

Both these odds have a confidence intervall way above one, as opposed to the number of reviews: with 95% probability, one more review does not change the odds of the latest review to have any higher star rating.


[Describe what you found through your analysis of the data]

-> Is the primary statistical model, statistical inference or prediction output in the results summarized and interpreted or is raw output given without description or interpretation?
  -> 1: The results are summarized and interpreted in a useful way

-> Is there a description of how the results relate to the primary questions of interest, or is it otherwise clear? In other words, do not give a point if the results seem unrelated to the question of interest and there is no apparent relationship.
  -> Was the primary question of interest answered / refuted or was there a description of why no clear answer could be obtained?
  
-> https://class.coursera.org/dsscapstone-005/wiki/Yelp_Final_Project_Rubric

  
# Discussion

Explain how you interpret the results of your analysis and what the implications are for your question/problem.


Problems with Ologit:

* proportional odds assumption not tested here - just assumed
* Diagnostics: Doing diagnostics for non-linear models is difficult, and ordered logit/probit models are even more difficult than binary models.

------------------------------------




```{r}
# Following http://www.ats.ucla.edu/stat/r/dae/ologit.htm

# First add a new variable to agg.ratings that is just last.rating converted to a factor, since polr requires this
agg.ratings$stars <- as.factor(agg.ratings$last.rating)
library(MASS)
m <- polr(stars ~ base.avg.rating + recent.avg.rating, data = agg.ratings, Hess=TRUE)
summary(m)

# Calculate p-values for the coefficients:
coefficients <- coef(summary(m))

# calculate and store p values
p <- pnorm(abs(coefficients[, "t value"]), lower.tail = FALSE) * 2
# combined table
(coefficients <- cbind(coefficients, "p value" = p))
# Get confidence intervals for the coefficients: 
(ci <- confint(m)) # default method gives profiled CIs
```

So both the 'base rating' and the recent avg rating 'influence a new rating: the confidence interval for both variables doesn't include 0.

This says that for a one unit increase in the recent.avg.rating, we can assume a 1.5 increase in the expected value of last.rating on the log odds scale, //if// base.avg.rating is kept constant.

Convert the log odds ratios to the easier interpretable Odds Ratios:
```{r}

# odds ratios
exp(coef(m))
# Confidence intervals for the odds ratios
exp(cbind(OR = coef(m), ci))
```

If the value of base.avg.rating moves one unit (e.g. from 1 to 2), the odds of moving from a 1-star last.rating to a higher rating is multiplied by 1.8
Similarily, if the value of recent.avg.rating moves one unit (e.g. from 1 to 2), the odds of moving from a 1-star last.rating to a higher rating is roughly doubled.


## Influence of country and the number of reviews at the time of the last rating


```{r}

m2 <- polr(stars ~ base.avg.rating + recent.avg.rating + num.reviews + country, data = agg.ratings[ agg.ratings$country != 'DE', ], Hess=TRUE)
summary(m2)

# Calculate p-values for the coefficients:
coefficients2 <- coef(summary(m2))

# calculate and store p values
p2 <- pnorm(abs(coefficients2[, "t value"]), lower.tail = FALSE) * 2
# combined table
(coefficients2 <- cbind(coefficients2, "p value" = p2))
# Get confidence intervals for the coefficients: 
(ci2 <- confint(m2)) # default method gives profiled CIs

# odds ratios
exp(coef(m2))
# Confidence intervals for the odds ratios
exp(cbind(OR = coef(m2), ci2))

```

So number of reviews and country don't affect the rating, and the relations between both the base average rating and recent average rating with a new rating hold, even if we control for the number of reviews and country.

## Are ratings that differ from the recent.avg.rating voted as more 'useful'?
  
* calculate difference of new rating and recent.avg.rating in terms of stdev
* correlate with 'useful'ness


```{r}
valid.sds <- which(agg.ratings$recent.sd > 0)
agg.ratings.with.sd <- agg.ratings[ valid.sds, ]
agg.ratings.with.sd$deviation <- abs(agg.ratings.with.sd$recent.avg.rating - agg.ratings.with.sd$last.rating) / agg.ratings.with.sd$recent.sd
agg.ratings.with.sd$diff <- abs(agg.ratings.with.sd$recent.avg.rating - agg.ratings.with.sd$last.rating) 

p1 <- ggplot(agg.ratings.with.sd, aes(deviation, useful)) + geom_point()
p2 <- ggplot(agg.ratings.with.sd, aes(diff, useful)) + geom_point()
multiplot(p1, p2, cols = 2)

cor(agg.ratings.with.sd$deviation, agg.ratings.with.sd$useful)
cor(agg.ratings.with.sd$diff, agg.ratings.with.sd$useful)

rcorr(as.matrix(agg.ratings.with.sd[,c("deviation", "diff", "useful")]), type="spearman")
```

There is no correlation between the deviation of the last rating form the recent average and the 'usefulness', i.e. the number of times a review got the vote 'useful'.

But graphically it looks like differing ratings tend to be less likely to get voted as 'useful', and, correspondingly, ratings that agree with older ratings tend to get more 'useful' votes.



# References

[aesch]: Asch, S. E. (1952a). Effects of group pressure on the modification and distortion of judgements. In G. E. Swanson, T. M. Newcomb & E. L. Hartley (Eds.), Readings in social psychology (2nd ed., pp. 2???11). New York:NY Holt.
[ologit]: See Wikipedia entry of "[Ordered Logit]"(https://en.wikipedia.org/wiki/Ordered_logit), and, more thoroughly: http://www.ats.ucla.edu/stat/r/dae/ologit.htm
